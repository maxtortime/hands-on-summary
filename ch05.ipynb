{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5장 - Support Vector Machine\n",
    "## 선형 SVM 분류\n",
    "SVM 분류기는 클래스 사이에 가장 폭이 넓은 도로를 찾는 것으로 생각 할 수 있어서 **라지 마진 분류**라고 한다. 각 경계에 위치한 샘플을 **서포트 벡터** 라고 한다. SVM도 스케일 통일이 중요하다\n",
    "\n",
    "## 소프트 마진 분류\n",
    "모든 샘플이 도로 바깥쪽에 분류되어 있으면 **Hard Margin Classification** 이라고 부른다. 하드 마진 분류의 문제점은 데이터가 선형적으로 구분될 수 있어야 잘 동작하고 이상치에 민감하다. 그래서 유연하게 도로의 폭을 넓히거나 **Margin Violation** (샘플이 도로 중간이나 반대에 있는 경우, 역주행?) 을 잡아야 하는데 이런 것을 **Soft Margin Classification** 이라고 한다.\n",
    "\n",
    "사이킷런에서는 C 하이퍼파라미터로 균형을 조절하는데 C 값과 마진 오류는 반비례한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data'][:, (2, 3)] # 꽃잎 길이, 꽃잎 너비\n",
    "y = (iris['target'] == 2).astype(np.float64)\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge'))\n",
    "])\n",
    "\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비선형 SVM 분류\n",
    "\n",
    "비선형 데이터셋은 4장처럼 다항 특성과 같은 특성을 추가하는 것이다. 하지만 낮은 차슈는 복잡한 데이터셋을 잘 표현하지 못하고 높은 차수는 모델이 느려진다. 다행히 SVM은 커널 트릭이라는 실제로 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것 같은 효과를 누릴 수 있다.\n",
    "\n",
    "이떄 모델이 오버피팅되면 차수를 줄여야하고 과소적합이면 차수를 늘려야 한다. coef0이 모델이 높은 차수와 낮은 차수에 영향을 얼마나 받을지 조절한다. 적절한 하이퍼파라미터를 찾으려면 그리드 탐색을 하는 것이 좋다.\n",
    "\n",
    "샘플이 특정 랜드마크와 얼마나 닮았는지 추정하는 유사도 함수로 계산한 특성을 추가하는 것도 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('poly_features', PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, loss='hinge'))\n",
    "])\n",
    "\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', SVC(C=5, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='poly', degree=3, coef0=1, C=5))\n",
    "])\n",
    "\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 연습문제\n",
    "\n",
    "1. SVM의 근본 아이디어는?\n",
    "\n",
    "구분해야 하는 각 클래스 사이에 가장 폭이 넓은 도로를 찾는 알고리즘이라고 할 수 있다. 여기서 도로라는 것은 도로의 경계는 각 클래스의 경계값을 이용해서 직선을 그은 것이고 중앙선은 각 경계로부터 최대한 멀리 떨어져야 샘플들이 혼동 없이 구분될 것이다\n",
    "\n",
    "2. 서포트 벡터란?\n",
    "\n",
    "서포트 벡터는 위에서 말한 것처럼 선을 긋기 위해 사용되는 클래스 별 샘플들의 경계값을 말한다.\n",
    "\n",
    "3. SVM의 입력값의 스케일이 중요한 이유는?\n",
    "\n",
    "어느 한 축의 스케일이 커버리면 도로의 기울기가 무척 작아지기 때문에 결정 경계가 좋아지지 않는다.\n",
    "\n",
    "4. SVM이 샘플을 분류할떄 신뢰도 점수나 확률을 출력할 수 있는지?\n",
    "\n",
    "책만 보면 그렇지 않은 것 같다.\n",
    "\n",
    "8. MNIST 와 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ova_clf = OneVsRestClassifier(LinearSVC(C=100, loss='hinge'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist['data'], mnist['target']\n",
    "X.shape # 784 = 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 60000\n",
    "X_train, X_test, y_train, y_test = X[:size], X[size:], y[:size], y[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(size)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 5000\n",
    "\n",
    "# X_train, y_train = X_train[:size], y_train[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=100, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ova_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86214077, 0.86935511, 0.86408333, 0.87063433, 0.87620874])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(ova_clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
